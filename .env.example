# === Configurações de API ===

# === OpenAI ===
OPENAI_API_KEY=sua_chave_api_openai_aqui

# === LangSmith ===
LANGSMITH_API_KEY=sua_chave_api_langsmith_aqui

# === Search Tools ===
TAVILY_API_KEY=sua_chave_api_tavily_aqui
GOOGLE_API_KEY=sua_chave_api_google_aqui
GOOGLE_CSE_ID=seu_cse_id_google_aqui

# === Firecrawl ===
FIRECRAWL_API_KEY=sua_chave_api_firecrawl_aqui


# === Configurações de Modelos ===
# Configuração de qual modelo usar em cada etapa do pipeline
MODEL_DOWNLOAD=local
MODEL_PARSING=local
MODEL_SEMANTIC_LINKING=gpt-4
MODEL_OUTPUT_GENERATION=gpt-3.5-turbo
MODEL_SUPERVISOR=gpt-4
MODEL_TOKEN_ANALYST=local


# === Configurações de Processamento ===
# Habilitar/desabilitar etapas específicas do pipeline
ENABLE_SUPERVISION=true
ENABLE_TOKEN_ANALYSIS=true
ENABLE_EXECUTION_HISTORY=true

# Verbosidade do logging (debug, info, warning, error)
LOG_LEVEL=info


# Limite de tokens por chamada para evitar gastos inesperados
MAX_TOKENS_PER_CALL=4000

# Opções para escalabilidade
USE_MAX_NODE=false  # Ativar apenas para processamento em lote ou paralelismo
MAX_CONCURRENT_TASKS=1  # Número de tarefas concorrentes quando MAX_NODE está ativo
