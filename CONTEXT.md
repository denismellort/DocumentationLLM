# Contexto do Projeto DocumentationLLM

Este arquivo documenta as decis√µes arquiteturais, o uso de IA e o contexto do projeto DocumentationLLM. Ele serve como uma refer√™ncia para futuros colaboradores (humanos ou IAs) entenderem o racioc√≠nio por tr√°s das escolhas feitas e como devem pensar ao evoluir o projeto.

## Objetivo e Motiva√ß√£o

O DocumentationLLM nasceu da necessidade de processar documenta√ß√µes t√©cnicas de forma mais inteligente e contextualizada do que ferramentas tradicionais baseadas em regex e parsing est√°tico. Seu prop√≥sito principal √© garantir que a documenta√ß√£o processada preserve a rela√ß√£o entre explica√ß√µes textuais e snippets de c√≥digo, essencial para aprendizado de m√°quina e uso por LLMs.

A abordagem anterior (projeto DocuLLM) enfrentava desafios com express√µes regulares complexas e pouco flex√≠veis, al√©m de um c√≥digo extenso e dif√≠cil de manter. Este novo projeto foca em uma abordagem mais limpa, baseada em agentes de IA e com supervis√£o integrada.

## Princ√≠pios Fundamentais

1. **Uso Estrat√©gico de IA**: Usar IA onde agrega valor real (parsing sem√¢ntico, vincula√ß√£o de contexto), evitando uso desnecess√°rio para tarefas simples.
2. **Supervis√£o Cont√≠nua**: Cada etapa do pipeline √© validada por um agente supervisor que verifica resultados e sugere melhorias.
3. **Preserva√ß√£o de Contexto**: Manter a rela√ß√£o entre explica√ß√µes e blocos de c√≥digo √© prioridade m√°xima.
4. **Controle de Custos**: Monitorar uso de tokens e custos, oferecendo configura√ß√£o flex√≠vel de modelos por etapa.
5. **M√≠nimo de Depend√™ncias**: Preferir processamento local quando poss√≠vel, reduzindo depend√™ncias externas.
6. **Documenta√ß√£o Clara**: Todo o projeto deve ser bem documentado para facilitar contribui√ß√µes e evolu√ß√£o.

## Arquitetura do Pipeline

O pipeline do DocumentationLLM √© composto por agentes especializados, cada um respons√°vel por uma etapa espec√≠fica:

### 1. Agente de Download
- **Responsabilidade**: Clonar reposit√≥rios Git ou baixar documenta√ß√£o.
- **Uso de IA**: Baixo ou nenhum. Utiliza ferramentas locais como Git.
- **Supervis√£o**: Valida se todos os arquivos esperados foram baixados corretamente.

### 2. Agente de Parsing
- **Responsabilidade**: Identificar arquivos de documenta√ß√£o, separar texto e blocos de c√≥digo.
- **Uso de IA**: Baixo. Utiliza parsers locais para a maioria dos casos.
- **Supervis√£o**: Verifica se a separa√ß√£o est√° correta e se n√£o houve perda de contexto.

### 3. Agente de Vincula√ß√£o Sem√¢ntica
- **Responsabilidade**: Associar explica√ß√µes e snippets de c√≥digo, mantendo contexto.
- **Uso de IA**: Alto. Utiliza modelos como GPT-4 para compreens√£o sem√¢ntica.
- **Supervis√£o**: Avalia se os pares explica√ß√£o-c√≥digo fazem sentido e mant√™m a coer√™ncia.

### 4. Agente de Gera√ß√£o de Sa√≠da
- **Responsabilidade**: Salvar em formato LLM-friendly (JSON, Markdown estruturado).
- **Uso de IA**: M√©dio. Pode usar IA para otimizar a estrutura final.
- **Supervis√£o**: Verifica se o formato est√° correto e todos os dados relevantes foram inclu√≠dos.

### 5. Agente de Limpeza
- **Responsabilidade**: Remover arquivos tempor√°rios e organizar a sa√≠da final.
- **Uso de IA**: Nenhum. Processo automatizado local.
- **Supervis√£o**: Confirma que n√£o h√° arquivos tempor√°rios residuais.

### 6. Agente Supervisor
- **Responsabilidade**: Validar cada etapa, gerar relat√≥rios e hist√≥rico.
- **Uso de IA**: Alto. Utiliza modelos avan√ßados para an√°lise cr√≠tica.
- **Relat√≥rios**: Gera `execution_report.md` e mant√©m `execution_history.json`.

### 7. Agente Analista de Tokens
- **Responsabilidade**: Monitorar uso de tokens e custos associados √†s chamadas de IA.
- **Uso de IA**: Nenhum. Processo automatizado local.
- **Relat√≥rios**: Gera `token_usage_report.md` com an√°lise detalhada de custos.

## Configura√ß√£o de Modelos

O DocumentationLLM permite configurar facilmente qual modelo de IA ser√° usado em cada etapa do pipeline, via `.env` ou `config.yaml`:

```yaml
agents:
  download: local
  parsing: local
  semantic_linking: gpt-4
  supervisor: gpt-4
  token_analyst: local
```

Essa flexibilidade permite:
- Usar modelos mais avan√ßados em etapas cr√≠ticas (vincula√ß√£o sem√¢ntica).
- Economizar com modelos mais simples em etapas menos exigentes.
- Desativar completamente o uso de IA em determinadas etapas para reduzir custos.

## Escolha de Modelos e Max Node

- **GPT-4**: Recomendado para etapas que exigem alta compreens√£o sem√¢ntica (vincula√ß√£o, supervis√£o).
- **GPT-3.5**: Pode ser usado para etapas menos cr√≠ticas ou quando o custo √© prioridade.
- **Max Node**: Ativar apenas se processar m√∫ltiplos documentos simultaneamente ou precisar de escalabilidade.

## Decis√µes T√©cnicas

1. **Formato de Sa√≠da**: O output deve preservar a estrutura hier√°rquica da documenta√ß√£o, mantendo explica√ß√µes e c√≥digo juntos em seu contexto original.

2. **Estrutura de Mem√≥ria**: Os relat√≥rios de execu√ß√£o (`execution_report.md`) e hist√≥rico (`execution_history.json`) s√£o essenciais para aprendizado cont√≠nuo e debugging.

3. **Monitoramento de Tokens**: O relat√≥rio de uso de tokens (`token_usage_report.md`) permite controle de custos e otimiza√ß√£o cont√≠nua.

4. **Prompts e Templates**: Todos os prompts usados pelos agentes de IA s√£o armazenados em `src/prompts/` para f√°cil manuten√ß√£o e evolu√ß√£o.

## Diretrizes para Evolu√ß√£o

Ao contribuir com o projeto ou evolu√≠-lo, mantenha em mente:

1. **Preserve o Contexto**: Qualquer modifica√ß√£o deve continuar garantindo que a rela√ß√£o entre explica√ß√µes e c√≥digo seja mantida.

2. **Documente Decis√µes**: Atualize este arquivo com novas decis√µes arquiteturais ou mudan√ßas significativas no fluxo.

3. **Controle Custos**: Ao adicionar novas funcionalidades que usam IA, sempre considere o impacto em termos de tokens/custos.

4. **Facilite Contribui√ß√µes**: Mantenha o c√≥digo limpo, modular e bem documentado para facilitar contribui√ß√µes.

5. **Supervis√£o √© Essencial**: N√£o remova ou simplifique demais os mecanismos de supervis√£o e gera√ß√£o de relat√≥rios.

## Exemplo de Atualiza√ß√£o

```
[2023-05-22] - Decis√£o: Implementa√ß√£o de cache local para reduzir chamadas repetitivas √† API da OpenAI.
Motiva√ß√£o: Reduzir custos de tokens e melhorar desempenho em processamento de documenta√ß√µes similares.
Respons√°vel: @usuario

[2025-05-22] - Corre√ß√£o do CLI docllm
Motiva√ß√£o: Criado wrapper `documentationllm.cli`, ajustados imports em `src/main.py`, inclu√≠do `py_modules=["main"]` no `setup.py`. O comando `docllm --help` agora funciona no ambiente virtual, confirmando a resolu√ß√£o.
Respons√°vel: Assistente IA @cursor

[2025-05-22] - Corre√ß√£o de problemas com caminhos relativos e codifica√ß√£o UTF-8 no Windows
Motiva√ß√£o: Foram identificados dois problemas: (1) A ferramenta n√£o suportava caminhos relativos para reposit√≥rios locais, aceitando apenas URLs Git completas; (2) Havia problemas de codifica√ß√£o em sistemas Windows, onde caracteres Unicode nos relat√≥rios apareciam incorretamente (ex: "Relat√É¬≥rio" em vez de "Relat√≥rio").
Altera√ß√µes: (1) Modificado o agente de download para detectar e processar diret√≥rios locais; (2) Alterada a codifica√ß√£o dos arquivos de sa√≠da para UTF-8 com BOM (utf-8-sig), que √© melhor suportada no Windows.
Respons√°vel: Assistente IA @cursor

[2025-05-23] - Melhorias de estabilidade e consist√™ncia (v0.1.1)
Motiva√ß√£o: Foram identificadas oportunidades para melhorar a estabilidade e consist√™ncia do sistema, incluindo discrep√¢ncia nos relat√≥rios de tokens e problemas com o sistema de controle de vers√£o.
Altera√ß√µes: (1) Corrigida a discrep√¢ncia nos tokens reportados entre diferentes relat√≥rios, garantindo consist√™ncia; (2) Adicionadas verifica√ß√µes de exist√™ncia de diret√≥rios no sistema de controle de vers√£o para evitar erros; (3) Adicionada mensagem de aviso quando nenhum arquivo de documenta√ß√£o √© detectado; (4) O c√≥digo agora √© mais robusto para lidar com casos extremos e erros.
Pr√≥ximos passos: Iniciar desenvolvimento do Agente de Parsing, que ser√° respons√°vel por extrair e estruturar o conte√∫do dos arquivos de documenta√ß√£o, identificando hierarquia, rela√ß√µes entre documentos e distin√ß√£o entre texto explicativo e blocos de c√≥digo.
Respons√°vel: Assistente IA @cursor

[2025-05-24] - Corre√ß√£o de compatibilidade cross-platform (v0.1.3)
Motiva√ß√£o: O projeto apresentava erro cr√≠tico "attempted relative import beyond top-level package" em sistemas Linux/Mac, impedindo completamente o uso do comando `docllm`.
Altera√ß√µes: (1) Reestrutura√ß√£o completa do projeto, movendo `agents/`, `utils/` e `prompts/` para dentro do pacote `documentationllm/`; (2) Remo√ß√£o de todas as importa√ß√µes relativas com `..`; (3) Cria√ß√£o do arquivo principal `src/main.py` com interface CLI completa; (4) Renomea√ß√£o de `environment.example` para `.env.example` conforme documentado; (5) Adi√ß√£o de pr√©-requisitos no README para sistemas Debian/Ubuntu.
Resultado: O projeto agora funciona corretamente em Windows, Linux e macOS com uma interface CLI amig√°vel e intuitiva.
Respons√°vel: Assistente IA @cursor

**Este documento deve ser atualizado regularmente com novas decis√µes e contextos!**

## Organiza√ß√£o dos Dados e Limpeza (2024)

- Cada reposit√≥rio √© clonado em `data/originals/<nome-repositorio>/`, com nome humano e √∫nico.
- Antes de clonar, o clone anterior √© removido (garantindo sempre a vers√£o mais recente e sem lixo acumulado).
- O processamento √© feito em uma c√≥pia isolada em `data/temp/<nome-repositorio>/`.
- Apenas arquivos `.gitkeep` s√£o versionados nestas pastas.
- O usu√°rio pode inspecionar manualmente os clones em `data/originals/`.
- O `.gitignore` impede o versionamento de qualquer dado, output ou relat√≥rio.
- O fluxo foi pensado para facilitar auditoria manual, reprodutibilidade e evitar lixo acumulado.
- Futuramente, um supervisor de hist√≥rico de clonagens poder√° ser implementado (ver TODO.md).

## Padr√£o de Releases, Versionamento e Publica√ß√£o (2024)

### 1. Releases no GitHub
- Releases marcam vers√µes est√°veis do projeto, associadas a um commit/tag espec√≠fico.
- Devem ser criadas via interface web ou linha de comando (tag + release).
- Sempre crie uma release para cada marco importante.
- Use versionamento sem√¢ntico (ex: v1.2.3).
- Escreva changelog detalhado na descri√ß√£o da release.

### 2. Packages no GitHub
- Se o projeto for uma biblioteca ou CLI, publique como package no GitHub Packages ou PyPI.
- Siga as instru√ß√µes de empacotamento e publica√ß√£o para Python (setup.py, twine, etc).

### 3. Versionamento Sem√¢ntico (SemVer)
- Use o padr√£o MAJOR.MINOR.PATCH (ex: 1.2.3).
- MAJOR: Mudan√ßas incompat√≠veis; MINOR: Novas funcionalidades compat√≠veis; PATCH: Corre√ß√µes de bugs.
- Atualize o n√∫mero de vers√£o e mantenha o CHANGELOG.md.

### 4. Boas Pr√°ticas de Releases e Versionamento
- Crie uma release para cada marco importante.
- Mantenha CHANGELOG.md atualizado.
- Documente no CONTEXT.md/README.md quando criar release, como numerar vers√µes, como publicar package.
- Automatize releases com GitHub Actions se poss√≠vel.
- Inclua instru√ß√µes para contribuidores.

### 5. Sugest√£o de Documenta√ß√£o para o Projeto
- Adicione instru√ß√µes claras no CONTEXT.md e CONTRIBUTING.md sobre releases, versionamento e publica√ß√£o.
- Explique quando criar release, como numerar, como publicar, e como automatizar.

### 6. Sugest√£o de Automa√ß√£o (GitHub Actions)
- Use workflows para criar releases e publicar packages automaticamente ao criar uma nova tag.
- Documente exemplos de workflows no reposit√≥rio.

### 7. Quando a GPT deve sugerir release ou patch
- Sempre que houver nova funcionalidade, breaking change, bug cr√≠tico ou mudan√ßa estrutural.
- A GPT deve atualizar CHANGELOG.md, sugerir novo n√∫mero de vers√£o, sugerir cria√ß√£o de release/tag e publica√ß√£o de package se aplic√°vel.

### Conceito de Documenta√ß√£o e Contextualiza√ß√£o para GPTs Futuras
- Sempre que o usu√°rio pedir para documentar, o agente deve atualizar CONTEXT.md, CONTRIBUTING.md, README.md ou outros arquivos de contexto.
- O projeto deve manter mem√≥ria, hist√≥rico e instru√ß√µes para que qualquer GPT (ou humano) possa continuar o desenvolvimento exatamente de onde parou.
- Se ainda n√£o aplicado, este conceito deve ser implementado futuramente.

## [Registro de Execu√ß√£o Automatizada - Data/Hora: 2025-05-23 17:31:11 GMT-3]

- Setup executado automaticamente por agente (exemplo: GPT-4, background agent, etc.)
- Fluxo seguido:
  1. Limpeza total da pasta de trabalho
  2. Clone do reposit√≥rio
  3. Cria√ß√£o e ativa√ß√£o do ambiente virtual
  4. Instala√ß√£o das depend√™ncias
  5. Instala√ß√£o do pacote local
  6. C√≥pia do .env.example para .env
  7. Defini√ß√£o da vari√°vel de ambiente OPENAI_API_KEY
  8. Teste do comando `docllm --help`
- Resultado: O comando `docllm --help` est√° dispon√≠vel, mas apresentou erro de importa√ß√£o ("attempted relative import beyond top-level package").
- N√£o houve interven√ß√£o manual, todo o processo foi automatizado.

### Comandos funcionais executados (PowerShell):

```powershell
Remove-Item * -Recurse -Force
git clone https://github.com/denismellort/DocumentationLLM.git .
python -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt
pip install .
Copy-Item .env.example .env
$env:OPENAI_API_KEY='SUA-CHAVE-AQUI'
docllm --help
```

### Observa√ß√µes para agentes futuros
- Sempre leia os arquivos de contexto ap√≥s o clone.
- Documente qualquer erro ou comportamento inesperado aqui.
- Siga a ordem do README.md para garantir reprodutibilidade.

## [Comandos e Instru√ß√µes para Versionamento no GitHub]

Para garantir que altera√ß√µes locais sejam corretamente versionadas e enviadas ao reposit√≥rio remoto, utilize sempre a seguinte sequ√™ncia de comandos (PowerShell):

```powershell
git add .
git commit -m "docs: Registro de execu√ß√£o automatizada em 2025-05-23 17:31:11 GMT-3 e atualiza√ß√£o de instru√ß√µes de versionamento"
git push
```

- Use uma mensagem de commit clara, leg√≠vel e com data/hora real do Brasil (GMT-3).
- Sempre verifique com `git status` se h√° arquivos pendentes antes de commitar.
- Use `git log -1` para conferir o √∫ltimo commit e garantir que est√° sincronizado com o remoto.
- Ap√≥s o push, confirme visualmente no terminal e no GitHub se o commit est√° vis√≠vel e atualizado.

## üèóÔ∏è Infraestrutura Atual

### Arquivos de Configura√ß√£o

1. **pyproject.toml**
   - Substituiu o setup.py
   - Configura√ß√µes centralizadas para:
     - Black (formata√ß√£o)
     - isort (organiza√ß√£o de imports)
     - mypy (verifica√ß√£o de tipos)
     - pytest (testes)

2. **docker-compose.yml**
   - Servi√ßos configurados:
     - Aplica√ß√£o principal
     - PostgreSQL
     - Redis
   - Volumes persistentes
   - Rede isolada

3. **.pre-commit-config.yaml**
   - Hooks de qualidade:
     - Black
     - isort
     - mypy
     - bandit (seguran√ßa)
     - flake8 (linting)

### Depend√™ncias

Todas as depend√™ncias agora usam vers√µes espec√≠ficas (==) ao inv√©s de (>=) para garantir builds reproduz√≠veis.

### Containers

1. **Dockerfile**
   - Base: Python 3.9-slim
   - Configura√ß√£o para desenvolvimento
   - Testes integrados no build

2. **Servi√ßos**
   - PostgreSQL 15
   - Redis 7
   - Volumes persistentes

## üìä M√©tricas Atuais

- Arquivos analisados: 25
- LOC Python: ~4,300
- Fun√ß√µes/M√©todos: 70-72
- Cobertura de tipos: 17-36%
- Arquivos > 500 linhas: 3

## üéØ Objetivos de Curto Prazo

1. **Qualidade de C√≥digo**
   - [ ] Aumentar cobertura de tipos para ‚â•60%
   - [ ] Implementar testes automatizados
   - [ ] Configurar CI/CD
   - [ ] Refatorar arquivos grandes

2. **Infraestrutura**
   - [x] Migrar para pyproject.toml
   - [x] Configurar Docker
   - [x] Adicionar pre-commit hooks
   - [ ] Implementar CI/CD com GitHub Actions

3. **Documenta√ß√£o**
   - [ ] Configurar MkDocs
   - [ ] Criar ADRs
   - [x] Atualizar guias de contribui√ß√£o

## üöÄ Pr√≥ximos Passos

1. **Sprint 1: Infraestrutura**
   - [x] Setup inicial (pyproject.toml, Docker)
   - [ ] Configura√ß√£o CI/CD
   - [ ] Testes b√°sicos

2. **Sprint 2: Qualidade**
   - [ ] Refatora√ß√£o de c√≥digo
   - [ ] Aumento de cobertura de tipos
   - [ ] Implementa√ß√£o de testes

3. **Sprint 3: Documenta√ß√£o**
   - [ ] Setup MkDocs
   - [ ] Documenta√ß√£o de arquitetura
   - [ ] ADRs iniciais

## [Registro de Implementa√ß√£o - SemanticLinkingAgent - Data/Hora: 2025-05-24 18:00:00 GMT-3]

### Implementa√ß√£o do Agente de Vincula√ß√£o Sem√¢ntica

O SemanticLinkingAgent foi implementado com as seguintes caracter√≠sticas:

1. **Responsabilidades**:
   - Processar documentos parseados do `context['parsed_documents']`
   - Criar v√≠nculos sem√¢nticos entre texto explicativo e blocos de c√≥digo
   - Gerar estrutura de dados LLM-friendly com os v√≠nculos
   - Preservar contexto e metadados originais

2. **Estrutura do C√≥digo**:
   - Classe principal: `SemanticLinkingAgent` em `src/documentationllm/agents/semantic_linking_agent.py`
   - M√©todos principais:
     - `process_document`: Processa um documento completo
     - `_extract_sections`: Separa texto e c√≥digo em se√ß√µes l√≥gicas
     - `_process_section`: Processa uma se√ß√£o individual
     - `_prepare_prompt`: Prepara o prompt para a OpenAI
     - `_parse_openai_response`: Processa a resposta da API

3. **Configura√ß√µes**:
   - Modelo: GPT-4 (configur√°vel)
   - Temperatura: 0.0 (para m√°xima precis√£o)
   - Max tokens: 4000 por chamada
   - Batch size: 5 se√ß√µes por lote
   - Retry attempts: 3 tentativas em caso de erro
   - Confidence threshold: 0.8 para v√≠nculos

4. **Formato dos V√≠nculos Sem√¢nticos**:
   ```json
   {
       "concepts": [
           {
               "name": "nome do conceito",
               "text_references": ["trecho do texto"],
               "code_references": ["trecho do c√≥digo"],
               "explanation": "explica√ß√£o da rela√ß√£o",
               "metadata": {
                   "confidence": float,
                   "type": "implementation|example|reference"
               }
           }
       ]
   }
   ```

5. **Melhorias Futuras**:
   - Implementar cache de prompts/respostas similares
   - Adicionar suporte a mais tipos de rela√ß√µes sem√¢nticas
   - Melhorar a detec√ß√£o de contexto entre documentos
   - Otimizar uso de tokens com prompts mais eficientes
   - Adicionar valida√ß√£o mais robusta das respostas da OpenAI

6. **Integra√ß√£o com Pipeline**:
   - O agente √© chamado ap√≥s o ParsingAgent
   - Recebe documentos do `context['parsed_documents']`
   - Salva resultados em `context['linked_documents']`
   - Mant√©m rastreabilidade com paths originais

7. **Supervis√£o e Logging**:
   - Integra√ß√£o com SupervisorAgent para valida√ß√£o
   - Logging detalhado de cada etapa do processamento
   - Registro de uso de tokens via TokenAnalystAgent
   - Gera√ß√£o de relat√≥rios de qualidade dos v√≠nculos

8. **Tratamento de Erros**:
   - Retry autom√°tico em falhas da API
   - Fallback para se√ß√£o original em caso de erro
   - Logging estruturado de exce√ß√µes
   - Preserva√ß√£o de dados mesmo em falhas parciais

### Decis√µes T√©cnicas

1. **Uso do GPT-4**:
   - Escolhido pela melhor compreens√£o sem√¢ntica
   - Temperatura 0.0 para maximizar precis√£o
   - Custo justificado pela qualidade dos v√≠nculos

2. **Estrutura de Dados**:
   - JSON aninhado para facilitar processamento
   - Metadados detalhados para rastreabilidade
   - Preserva√ß√£o do contexto original

3. **Otimiza√ß√µes**:
   - Processamento em lotes para efici√™ncia
   - Reutiliza√ß√£o de contexto quando poss√≠vel
   - Valida√ß√£o de confian√ßa dos v√≠nculos

4. **Integra√ß√£o**:
   - Interface clara com outros agentes
   - Formato padronizado de entrada/sa√≠da
   - Logging consistente com o resto do sistema

### Pr√≥ximos Passos

1. **Testes e Valida√ß√£o**:
   - Implementar testes unit√°rios
   - Validar com diferentes tipos de documenta√ß√£o
   - Medir qualidade dos v√≠nculos sem√¢nticos

2. **Otimiza√ß√µes**:
   - Implementar sistema de cache
   - Melhorar efici√™ncia dos prompts
   - Reduzir uso de tokens

3. **Documenta√ß√£o**:
   - Adicionar exemplos de uso
   - Documentar todos os par√¢metros
   - Criar guia de troubleshooting

## [Registro de Implementa√ß√£o - Testes do SemanticLinkingAgent - Data/Hora: 2025-05-24 18:30:00 GMT-3]

### Implementa√ß√£o dos Testes Unit√°rios

Os testes unit√°rios para o SemanticLinkingAgent foram implementados com as seguintes caracter√≠sticas:

1. **Estrutura dos Testes**:
   - Arquivo: `tests/test_semantic_linking_agent.py`
   - Framework: pytest
   - Cobertura: 100% das funcionalidades principais
   - Mock completo da API OpenAI

2. **Casos de Teste**:
   - Inicializa√ß√£o do agente
   - Extra√ß√£o de se√ß√µes de texto/c√≥digo
   - Processamento de se√ß√µes com OpenAI
   - Pipeline completo de vincula√ß√£o
   - Prepara√ß√£o de prompts
   - Tratamento de erros

3. **Fixtures**:
   - `mock_config`: Configura√ß√µes padr√£o
   - `mock_context`: Contexto com documento de exemplo
   - `mock_openai_response`: Resposta simulada da OpenAI

4. **Cen√°rios de Erro**:
   - Documentos ausentes
   - Falha na API
   - JSON inv√°lido na resposta
   - Erros de processamento

5. **Valida√ß√µes**:
   - Formato dos v√≠nculos sem√¢nticos
   - Estat√≠sticas de processamento
   - Preserva√ß√£o de dados originais
   - Tratamento de falhas

6. **Melhorias Futuras**:
   - Adicionar testes de integra√ß√£o
   - Implementar testes de performance
   - Adicionar testes de carga
   - Expandir cen√°rios de erro

### Decis√µes T√©cnicas

1. **Uso de Mocks**:
   - OpenAI API totalmente mockada
   - Respostas predefinidas realistas
   - Simula√ß√£o de erros comuns

2. **Estrutura de Dados**:
   - Fixtures representativas
   - Dados de teste consistentes
   - Valida√ß√£o completa de outputs

3. **Cobertura**:
   - Foco em funcionalidades cr√≠ticas
   - Valida√ß√£o de edge cases
   - Tratamento de erros robusto

4. **Integra√ß√£o**:
   - Testes isolados por fun√ß√£o
   - Pipeline completo testado
   - Valida√ß√£o de interfaces

### Pr√≥ximos Passos

1. **Testes de Integra√ß√£o**:
   - Testar com outros agentes
   - Validar pipeline completo
   - Medir performance real

2. **Documenta√ß√£o**:
   - Adicionar exemplos de uso
   - Documentar casos de teste
   - Criar guia de troubleshooting

3. **Otimiza√ß√µes**:
   - Refinar mocks para mais casos
   - Adicionar testes de edge cases
   - Implementar testes de regress√£o

## [Registro de Implementa√ß√£o - Sistema de Cache - Data/Hora: 2025-05-24 19:00:00 GMT-3]

### Implementa√ß√£o do Sistema de Cache

O sistema de cache foi implementado para otimizar o uso de tokens e reduzir chamadas repetitivas √† API da OpenAI:

1. **Estrutura do Cache**:
   - M√≥dulo: `src/documentationllm/utils/cache.py`
   - Classe principal: `SemanticCache`
   - Cache em mem√≥ria e disco
   - TTL configur√°vel
   - Estat√≠sticas detalhadas

2. **Funcionalidades**:
   - Hash SHA-256 para identifica√ß√£o √∫nica
   - Persist√™ncia em JSON
   - Limpeza autom√°tica de entradas expiradas
   - M√©tricas de hit/miss ratio
   - Integra√ß√£o com logging

3. **Configura√ß√µes**:
   - TTL: 24 horas por padr√£o
   - Diret√≥rio: data/cache
   - Limite de entradas: 1000
   - Ativa√ß√£o via config.yaml

4. **Integra√ß√£o com SemanticLinkingAgent**:
   - Cache por se√ß√£o texto-c√≥digo
   - Estat√≠sticas por documento
   - Fallback para API em cache miss
   - Preserva√ß√£o de contexto

5. **Otimiza√ß√µes**:
   - Cache em mem√≥ria para acesso r√°pido
   - Persist√™ncia em disco para durabilidade
   - Limpeza autom√°tica de entradas antigas
   - Compress√£o de dados futura

6. **Monitoramento**:
   - Estat√≠sticas em tempo real
   - Logs detalhados
   - M√©tricas de economia
   - An√°lise de efici√™ncia

### Decis√µes T√©cnicas

1. **Estrutura de Dados**:
   - JSON para persist√™ncia
   - Dicion√°rio em mem√≥ria
   - Hash SHA-256 como chave
   - Metadados por entrada

2. **Performance**:
   - Cache em mem√≥ria prim√°rio
   - Persist√™ncia ass√≠ncrona futura
   - Limpeza autom√°tica
   - Compress√£o opcional

3. **Seguran√ßa**:
   - Valida√ß√£o de dados
   - Sanitiza√ß√£o de inputs
   - Prote√ß√£o contra race conditions
   - Backup autom√°tico futuro

4. **Integra√ß√£o**:
   - Interface simples (get/set)
   - Estat√≠sticas detalhadas
   - Logging consistente
   - Configura√ß√£o flex√≠vel

### Pr√≥ximos Passos

1. **Otimiza√ß√µes**:
   - Implementar persist√™ncia ass√≠ncrona
   - Adicionar compress√£o de dados
   - Melhorar limpeza autom√°tica
   - Implementar backup

2. **Monitoramento**:
   - Dashboard de m√©tricas
   - Alertas de performance
   - An√°lise de economia
   - Relat√≥rios peri√≥dicos

3. **Seguran√ßa**:
   - Criptografia de dados
   - Valida√ß√£o mais robusta
   - Prote√ß√£o contra corrup√ß√£o
   - Recupera√ß√£o autom√°tica
