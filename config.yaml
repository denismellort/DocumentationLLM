# Configuração para DocumentationLLM

# Modelos para cada etapa
models:
  download: local
  parsing: local
  semantic_linking: gpt-4
  output_generation: gpt-3.5-turbo
  supervisor: gpt-4
  token_analyst: local

# Opções de processamento
processing:
  enable_supervision: true
  enable_token_analysis: true
  enable_execution_history: true
  log_level: info
  max_tokens_per_call: 4000

# Opções de escalabilidade
scaling:
  use_max_node: false
  max_concurrent_tasks: 1

# Diretórios padrão
directories:
  originals: data/originals
  processed: data/processed
  temp: data/temp 

# Configurações dos agentes
agents:
  semantic_linking:
    model: gpt-4
    temperature: 0.0
    max_tokens: 4000
    batch_size: 5  # Número de seções processadas por lote
    retry_attempts: 3  # Tentativas em caso de erro na API
    confidence_threshold: 0.8  # Limiar mínimo de confiança para vínculos semânticos 